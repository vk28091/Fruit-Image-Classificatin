{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fba0b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31c0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4d03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1/255,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed78e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9700 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(\"D:\\\\python\\\\Capstone Project\\\\New folder\\\\train\",\n",
    "                                              target_size=(64,64),\n",
    "                                              class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df1bc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 0, 'Banana': 1, 'Grape': 2, 'Mango': 3, 'Strawberry': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5712cd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_set=test_datagen.flow_from_directory(\"D:\\\\python\\\\Capstone Project\\\\New folder\\\\test\",\n",
    "                                         target_size=(64,64),\n",
    "                                         class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c947a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 0, 'Banana': 1, 'Grape': 2, 'Mango': 3, 'Strawberry': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07332549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling\n",
    "from keras.models import Sequential\n",
    "classifier=Sequential()\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "classifier.add(Conv2D(input_shape=[64,64,3],filters=32,kernel_size=3,activation=\"relu\"))\n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "classifier.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "classifier.add(Conv2D(input_shape=[64,64,3],filters=32,kernel_size=3,activation=\"relu\"))\n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "classifier.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "\n",
    "from keras.layers import Flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "from keras.layers import Dense\n",
    "classifier.add(Dense(units=128,activation=\"relu\"))\n",
    "classifier.add(Dense(units=5,activation=\"softmax\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b68bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd7b304",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "304/304 [==============================] - 484s 2s/step - loss: 1.1957 - accuracy: 0.4897 - val_loss: 1.0319 - val_accuracy: 0.5600\n",
      "Epoch 2/25\n",
      "304/304 [==============================] - 56s 183ms/step - loss: 1.0179 - accuracy: 0.5846 - val_loss: 0.9302 - val_accuracy: 0.6200\n",
      "Epoch 3/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.9336 - accuracy: 0.6253 - val_loss: 0.8823 - val_accuracy: 0.6000\n",
      "Epoch 4/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.8575 - accuracy: 0.6663 - val_loss: 0.8512 - val_accuracy: 0.6400\n",
      "Epoch 5/25\n",
      "304/304 [==============================] - 56s 183ms/step - loss: 0.7986 - accuracy: 0.6891 - val_loss: 0.9032 - val_accuracy: 0.6700\n",
      "Epoch 6/25\n",
      "304/304 [==============================] - 56s 183ms/step - loss: 0.7391 - accuracy: 0.7157 - val_loss: 0.9266 - val_accuracy: 0.7000\n",
      "Epoch 7/25\n",
      "304/304 [==============================] - 56s 183ms/step - loss: 0.6795 - accuracy: 0.7408 - val_loss: 1.1423 - val_accuracy: 0.5700\n",
      "Epoch 8/25\n",
      "304/304 [==============================] - 56s 183ms/step - loss: 0.6384 - accuracy: 0.7528 - val_loss: 0.9256 - val_accuracy: 0.6600\n",
      "Epoch 9/25\n",
      "304/304 [==============================] - 56s 184ms/step - loss: 0.5697 - accuracy: 0.7853 - val_loss: 1.0541 - val_accuracy: 0.6700\n",
      "Epoch 10/25\n",
      "304/304 [==============================] - 56s 184ms/step - loss: 0.5219 - accuracy: 0.7999 - val_loss: 0.8863 - val_accuracy: 0.6800\n",
      "Epoch 11/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.4638 - accuracy: 0.8307 - val_loss: 1.0185 - val_accuracy: 0.6900\n",
      "Epoch 12/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.4233 - accuracy: 0.8473 - val_loss: 1.0650 - val_accuracy: 0.6900\n",
      "Epoch 13/25\n",
      "304/304 [==============================] - 56s 184ms/step - loss: 0.3789 - accuracy: 0.8589 - val_loss: 1.2122 - val_accuracy: 0.6400\n",
      "Epoch 14/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.3498 - accuracy: 0.8732 - val_loss: 1.2725 - val_accuracy: 0.6800\n",
      "Epoch 15/25\n",
      "304/304 [==============================] - 56s 184ms/step - loss: 0.3099 - accuracy: 0.8872 - val_loss: 1.2767 - val_accuracy: 0.6500\n",
      "Epoch 16/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.2852 - accuracy: 0.9003 - val_loss: 1.5296 - val_accuracy: 0.6500\n",
      "Epoch 17/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.2572 - accuracy: 0.9075 - val_loss: 1.4194 - val_accuracy: 0.6500\n",
      "Epoch 18/25\n",
      "304/304 [==============================] - 57s 188ms/step - loss: 0.2239 - accuracy: 0.9223 - val_loss: 1.3810 - val_accuracy: 0.6500\n",
      "Epoch 19/25\n",
      "304/304 [==============================] - 56s 184ms/step - loss: 0.2097 - accuracy: 0.9279 - val_loss: 1.2893 - val_accuracy: 0.6800\n",
      "Epoch 20/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.1767 - accuracy: 0.9394 - val_loss: 1.4969 - val_accuracy: 0.6700\n",
      "Epoch 21/25\n",
      "304/304 [==============================] - 57s 186ms/step - loss: 0.1958 - accuracy: 0.9323 - val_loss: 1.7157 - val_accuracy: 0.6400\n",
      "Epoch 22/25\n",
      "304/304 [==============================] - 57s 187ms/step - loss: 0.1503 - accuracy: 0.9479 - val_loss: 1.4812 - val_accuracy: 0.6300\n",
      "Epoch 23/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.1447 - accuracy: 0.9498 - val_loss: 1.7124 - val_accuracy: 0.6600\n",
      "Epoch 24/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.1536 - accuracy: 0.9460 - val_loss: 1.7946 - val_accuracy: 0.7000\n",
      "Epoch 25/25\n",
      "304/304 [==============================] - 56s 185ms/step - loss: 0.1424 - accuracy: 0.9511 - val_loss: 1.7910 - val_accuracy: 0.6700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1961967f580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x=training_set,validation_data=test_set,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f61f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "219c925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "[3]\n",
      "mango\n"
     ]
    }
   ],
   "source": [
    "test_image=Image.open(\"D:\\\\python\\\\Capstone Project\\\\New folder\\\\Mango (28).jpeg\")\n",
    "\n",
    "\n",
    "test_image=test_image.resize((64,64))\n",
    "test_image=np.array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=classifier.predict(test_image)\n",
    "result=np.argmax(result,axis=1)\n",
    "\n",
    "print(result)\n",
    "if result[0]==0:\n",
    "    print(\"apple\")\n",
    "elif result[0]==1:\n",
    "    print(\"banana\")\n",
    "elif result[0]==2:\n",
    "    print(\"grape\")\n",
    "elif result[0]==3:\n",
    "    print(\"mango\")\n",
    "elif result[0]==4:\n",
    "    print(\"strawberry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f65c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f003a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
